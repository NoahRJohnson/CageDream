{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "'''Lots of code copied from here: \n",
    "    https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/examples/tutorials/deepdream/README.md\n",
    "    \n",
    "'''\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "!export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64\n",
    "!export PATH=$PATH:/home/noah/bin:/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin\n",
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n",
    "!export SWIG_PATH=/home/noah/swig/bin/swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function placeholder_with_default at 0x7f728dde6cf8>\n"
     ]
    }
   ],
   "source": [
    "# boilerplate code\n",
    "import os\n",
    "from cStringIO import StringIO\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.placeholder_with_default) # check to see if we have the right tensorflow version (r0.7 doesn't have this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "�\u0015\n",
      "\u0013DecodeJpeg/contents\u0012\u0005Const*\u000b",
      "\n",
      "\u0005dtype\u0012\u00020\u0007*�\u0015\n",
      "\u0005value\u0012�\u0015B�\u0015\b\u0007\u0012\u0000B�\u0014����\u0000\u0010JFIF\u0000\u0001\u0001\u0000\u0000\u0001\u0000\u0001\u0000\u0000��\u0000C\u0000\b\u0006\u0006\u0007\u0006\u0005\b\u0007\u0007\u0007\t\t\b\n",
      "\f",
      "\u0014\r",
      "\f",
      "\u000b",
      "\u000b",
      "\f",
      "\u0019\u0012\u0013\u000f\u0014\u001d",
      "\u001a\u001f\u001e",
      "\u001d",
      "\u001a\u001c",
      "\u001c",
      " $.' \",#\u001c",
      "\u001c",
      "(7),01444\u001f'9=82<.342��\u0000C\u0001\t\t\t\f",
      "\u000b",
      "\f",
      "\u0018\r",
      "\r",
      "\u00182!\u001c",
      "!22222222222222222222222222222222222222222222222222��\u0000\u0011\b\u0000d\u0000d\u0003\u0001\"\u0000\u0002\u0011\u0001\u0003\u0011\u0001��\u0000\u001c",
      "\u0000\u0000\u0001\u0004\u0003\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0006\u0000\u0004\u0005\u0007\u0001\u0002\u0003\b��\u00005\u0010\u0000\u0002\u0001\u0003\u0002\u0004\u0005\u0001\u0006\u0006\u0003\u0001\u0000\u0000\u0000\u0000\u0001\u0002\u0003\u0000\u0004\u0011\u0005!\u0006\u00121A\u0013\"Qaq�\u00072����\u0014\u0015#BR�b�����\u0000\u0019\u0001\u0000\u0003\u0001\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0002\u0003\u0004\u0000\u0001\u0005��\u0000\u001f\u0011\u0000\u0002\u0002\u0003\u0001\u0001\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0002\u0011\u0003\u0012!1\u0013\u00042Q��\u0000\f",
      "\u0003\u0001\u0000\u0002\u0011\u0003\u0011\u0000?\u0000\u0012��'�x���]qo#\u000b",
      "��\u0003���|�mR�\r",
      "'J�yJ\"\"�\u0014�\f",
      "�\u0014=�I\b����.T�ו�<�l���\u0002k��79�`Ȥ��soҙ\u000f���w&�a�q%��x�΋\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f43d329f490>> ignored\n",
      "Exception AssertionError: AssertionError() in <generator object get_controller at 0x7f43d73a7af0> ignored\n"
     ]
    }
   ],
   "source": [
    "model_fn = '/home/noah/git/CageDream/cage_graph.pb'\n",
    "\n",
    "# creating TensorFlow session and loading the model\n",
    "graph = tf.Graph()\n",
    "sess = tf.InteractiveSession(graph=graph)\n",
    "print open(model_fn).read()[:500] \"\"\"\n",
    "graph_def = tf.GraphDef.FromString(open(model_fn).read())\n",
    "t_input = tf.placeholder(np.float32, name='input') # define the input tensor\n",
    "imagenet_mean = 117.0\n",
    "t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
    "tf.import_graph_def(graph_def, {'input':t_preprocessed})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f43d7434110>> ignored\n",
      "Exception AssertionError: AssertionError() in <generator object get_controller at 0x7f43d759be60> ignored\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempted to map inputs that were not found in graph_def: [input:0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-be3cf772088d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mimagenet_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m117.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mt_preprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_input\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mimagenet_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt_preprocessed\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict)\u001b[0m\n\u001b[0;32m    347\u001b[0m       raise ValueError(\n\u001b[0;32m    348\u001b[0m           \u001b[1;34m'Attempted to map inputs that were not found in graph_def: [%s]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m           % ', '.join(unused_input_keys))\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_elements\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempted to map inputs that were not found in graph_def: [input:0]"
     ]
    }
   ],
   "source": [
    "modelFullPath = '/home/noah/git/CageDream/cage_graph.pb'\n",
    "# creating TensorFlow session and loading the model\n",
    "graph = tf.Graph()\n",
    "sess = tf.InteractiveSession(graph=graph)\n",
    "#graph_def = tf.GraphDef.FromString(open(model_fn).read())\n",
    "with tf.gfile.FastGFile(modelFullPath, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        t_input = tf.placeholder(np.float32, name='input') # define the input tensor\n",
    "        imagenet_mean = 117.0\n",
    "        t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
    "        _ = tf.import_graph_def(graph_def, {'input':t_preprocessed}, name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__int__ returned non-int (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c39caf24cf91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfeature_nums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m':0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Number of layers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __int__ returned non-int (type NoneType)"
     ]
    }
   ],
   "source": [
    "#layers = [op.name for op in graph.get_operations() if op.type=='Conv2D' and 'import/' in op.name]\n",
    "#feature_nums = [int(graph.get_tensor_by_name(name+':0').get_shape()[-1]) for name in layers]\n",
    "\n",
    "layers = [op.name for op in graph.get_operations()]\n",
    "feature_nums = [int(graph.get_tensor_by_name(name+':0').get_shape()[-1]) for name in layers]\n",
    "\n",
    "print 'Number of layers', len(layers)\n",
    "print 'Total number of feature channels:', sum(feature_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'import/mixed4d_3x3_bottleneck_pre_relu:0' refers to a Tensor which does not exist. The operation, 'import/mixed4d_3x3_bottleneck_pre_relu', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ce4876e3cc7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mshowarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mrender_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-ce4876e3cc7a>\u001b[0m in \u001b[0;36mT\u001b[1;34m(layer)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;34m'''Helper for getting layer output tensor'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"import/%s:0\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrender_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2216\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\"\n\u001b[0;32m   2217\u001b[0m                       % type(name).__name__)\n\u001b[1;32m-> 2218\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2220\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2113\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[0;32m   2114\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[0;32m   2116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'import/mixed4d_3x3_bottleneck_pre_relu:0' refers to a Tensor which does not exist. The operation, 'import/mixed4d_3x3_bottleneck_pre_relu', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "# Picking some internal layer. Note that we use outputs before applying the ReLU nonlinearity\n",
    "# to have non-zero gradients for features with negative initial activations.\n",
    "layer = 'mixed4d_3x3_bottleneck_pre_relu'\n",
    "channel = 138 # picking some feature channel to visualize\n",
    "\n",
    "# start with a gray image with a little noise\n",
    "img_noise = np.random.uniform(size=(224,224,3)) + 100.0\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def visstd(a, s=0.1):\n",
    "    '''Normalize the image range for visualization'''\n",
    "    return (a-a.mean())/max(a.std(), 1e-4)*s + 0.5\n",
    "\n",
    "def T(layer):\n",
    "    '''Helper for getting layer output tensor'''\n",
    "    return graph.get_tensor_by_name(\"import/%s:0\"%layer)\n",
    "\n",
    "def render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    \n",
    "    img = img0.copy()\n",
    "    print iter_n\n",
    "    for i in xrange(iter_n):\n",
    "        g, score = sess.run([t_grad, t_score], {t_input:img})\n",
    "        # normalizing the gradient, so the same step size should work \n",
    "        g /= g.std()+1e-8         # for different layers and networks\n",
    "        img += g*step\n",
    "        print score\n",
    "    clear_output()\n",
    "    showarray(visstd(img))\n",
    "\n",
    "render_naive(T(layer)[:,:,:,channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tffunc(*argtypes):\n",
    "    '''Helper that transforms TF-graph generating function into a regular one.\n",
    "    See \"resize\" function below.\n",
    "    '''\n",
    "    placeholders = map(tf.placeholder, argtypes)\n",
    "    def wrap(f):\n",
    "        out = f(*placeholders)\n",
    "        def wrapper(*args, **kw):\n",
    "            return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))\n",
    "        return wrapper\n",
    "    return wrap\n",
    "\n",
    "# Helper function that uses TF to resize an image\n",
    "def resize(img, size):\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    return tf.image.resize_bilinear(img, size)[0,:,:,:]\n",
    "resize = tffunc(np.float32, np.int32)(resize)\n",
    "\n",
    "\n",
    "def calc_grad_tiled(img, t_grad, tile_size=512):\n",
    "    '''Compute the value of tensor t_grad over the image in a tiled way.\n",
    "    Random shifts are applied to the image to blur tile boundaries over \n",
    "    multiple iterations.'''\n",
    "    sz = tile_size\n",
    "    h, w = img.shape[:2]\n",
    "    sx, sy = np.random.randint(sz, size=2)\n",
    "    img_shift = np.roll(np.roll(img, sx, 1), sy, 0)\n",
    "    grad = np.zeros_like(img)\n",
    "    for y in xrange(0, max(h-sz//2, sz),sz):\n",
    "        for x in xrange(0, max(w-sz//2, sz),sz):\n",
    "            sub = img_shift[y:y+sz,x:x+sz]\n",
    "            g = sess.run(t_grad, {t_input:sub})\n",
    "            grad[y:y+sz,x:x+sz] = g\n",
    "    return np.roll(np.roll(grad, -sx, 1), -sy, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_multiscale(t_obj, img0=img_noise, iter_n=10, step=1.0, octave_n=3, octave_scale=1.4):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    \n",
    "    img = img0.copy()\n",
    "    for octave in xrange(octave_n):\n",
    "        if octave>0:\n",
    "            hw = np.float32(img.shape[:2])*octave_scale\n",
    "            img = resize(img, np.int32(hw))\n",
    "        for i in xrange(iter_n):\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            # normalizing the gradient, so the same step size should work \n",
    "            g /= g.std()+1e-8         # for different layers and networks\n",
    "            img += g*step\n",
    "            print '.',\n",
    "        clear_output()\n",
    "        showarray(visstd(img))\n",
    "\n",
    "render_multiscale(T(layer)[:,:,:,channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Laplacian Pyramid functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = np.float32([1,4,6,4,1])\n",
    "k = np.outer(k, k)\n",
    "k5x5 = k[:,:,None,None]/k.sum()*np.eye(3, dtype=np.float32)\n",
    "\n",
    "def lap_split(img):\n",
    "    '''Split the image into lo and hi frequency components'''\n",
    "    with tf.name_scope('split'):\n",
    "        lo = tf.nn.conv2d(img, k5x5, [1,2,2,1], 'SAME')\n",
    "        lo2 = tf.nn.conv2d_transpose(lo, k5x5*4, tf.shape(img), [1,2,2,1])\n",
    "        hi = img-lo2\n",
    "    return lo, hi\n",
    "\n",
    "def lap_split_n(img, n):\n",
    "    '''Build Laplacian pyramid with n splits'''\n",
    "    levels = []\n",
    "    for i in xrange(n):\n",
    "        img, hi = lap_split(img)\n",
    "        levels.append(hi)\n",
    "    levels.append(img)\n",
    "    return levels[::-1]\n",
    "\n",
    "def lap_merge(levels):\n",
    "    '''Merge Laplacian pyramid'''\n",
    "    img = levels[0]\n",
    "    for hi in levels[1:]:\n",
    "        with tf.name_scope('merge'):\n",
    "            img = tf.nn.conv2d_transpose(img, k5x5*4, tf.shape(hi), [1,2,2,1]) + hi\n",
    "    return img\n",
    "\n",
    "def normalize_std(img, eps=1e-10):\n",
    "    '''Normalize image by making its standard deviation = 1.0'''\n",
    "    with tf.name_scope('normalize'):\n",
    "        std = tf.sqrt(tf.reduce_mean(tf.square(img)))\n",
    "        return img/tf.maximum(std, eps)\n",
    "\n",
    "def lap_normalize(img, scale_n=4):\n",
    "    '''Perform the Laplacian pyramid normalization.'''\n",
    "    img = tf.expand_dims(img,0)\n",
    "    tlevels = lap_split_n(img, scale_n)\n",
    "    tlevels = map(normalize_std, tlevels)\n",
    "    out = lap_merge(tlevels)\n",
    "    return out[0,:,:,:]\n",
    "\n",
    "# Showing the lap_normalize graph with TensorBoard\n",
    "lap_graph = tf.Graph()\n",
    "with lap_graph.as_default():\n",
    "    lap_in = tf.placeholder(np.float32, name='lap_in')\n",
    "    lap_out = lap_normalize(lap_in)\n",
    "show_graph(lap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_lapnorm(t_obj, img0=img_noise, visfunc=visstd,\n",
    "                   iter_n=10, step=1.0, octave_n=3, octave_scale=1.4, lap_n=4):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    # build the laplacian normalization graph\n",
    "    lap_norm_func = tffunc(np.float32)(partial(lap_normalize, scale_n=lap_n))\n",
    "\n",
    "    img = img0.copy()\n",
    "    for octave in xrange(octave_n):\n",
    "        if octave>0:\n",
    "            hw = np.float32(img.shape[:2])*octave_scale\n",
    "            img = resize(img, np.int32(hw))\n",
    "        for i in xrange(iter_n):\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            g = lap_norm_func(g)\n",
    "            img += g*step\n",
    "            print '.',\n",
    "        clear_output()\n",
    "        showarray(visfunc(img))\n",
    "\n",
    "render_lapnorm(T(layer)[:,:,:,channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "render_lapnorm(T(layer)[:,:,:,65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "render_lapnorm(T('mixed3b_1x1_pre_relu')[:,:,:,101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "render_lapnorm(T(layer)[:,:,:,65]+T(layer)[:,:,:,139], octave_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep Dream functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_deepdream(t_obj, img0=img_noise,\n",
    "                     iter_n=10, step=1.5, octave_n=4, octave_scale=1.4):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "\n",
    "    # split the image into a number of octaves\n",
    "    img = img0\n",
    "    octaves = []\n",
    "    for i in xrange(octave_n-1):\n",
    "        hw = img.shape[:2]\n",
    "        lo = resize(img, np.int32(np.float32(hw)/octave_scale))\n",
    "        hi = img-resize(lo, hw)\n",
    "        img = lo\n",
    "        octaves.append(hi)\n",
    "    \n",
    "    # generate details octave by octave\n",
    "    for octave in xrange(octave_n):\n",
    "        if octave>0:\n",
    "            hi = octaves[-octave]\n",
    "            img = resize(img, hi.shape[:2])+hi\n",
    "        for i in xrange(iter_n):\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            img += g*(step / (np.abs(g).mean()+1e-7))\n",
    "            print '.',\n",
    "        clear_output()\n",
    "        showarray(img/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img0 = PIL.Image.open('pilatus800.jpg')\n",
    "img0 = np.float32(img0)\n",
    "showarray(img0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "render_deepdream(tf.square(T('mixed4c')), img0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
